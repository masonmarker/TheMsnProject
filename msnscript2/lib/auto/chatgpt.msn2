# Grants capabilities for automating ChatGPT's website.
# 
# Why use this as opposed to OpenAI's ChatGPT API?
# A: 
#   1. No API key
#   2. No charge per request
#   3. Model settings pre-determined and refined by OpenAI's team
#   4. ChatGPT's algorithm for retaining and interpreting the previous messages
#      is maintained (THIS IS ABSOLUTELY HUGE AND CRUCIAL TO 
#      UTILIZING GPT'S COMPLETE CAPABILITIES)
#
# author : Mason Marker
# date : 6/2/2023
# updated in 2.0.387

# import automated JavaScript injection library
import ('lib/auto/inject')

# import the Chrome library for the default Chrome path
import ('lib/auto/chrome')

# asks ChatGPT questions, retrieving its answer
# only works for dark mode as of 2.0.387
function('chatgpt:ask_gpt', (

    # opens Google Chrome to the ChatGPT website
    @ ask_gpt:_chrome = app(chrome:default_path),
    ask_gpt:_chrome.start(),
    ask_gpt:_chrome.write('https://chat.openai.com/'),
    ask_gpt:_chrome.enter(),

    # waits for the message input to appear
    @ ask_gpt:_message_input = ask_gpt:_chrome.wait_for_input('Send a message'),

    # opens the inspect element panel
    ask_gpt:_chrome.inspect(),

    # responses from ChatGPT
    @ ask_gpt:_responses = [],

    # for each message
    ask_gpt:_messages.each('ask_gpt:_message', (

        # asks ChatGPT a question
        ask_gpt:_message_input.focus(),
        ask_gpt:_chrome.write(ask_gpt:_message),
        ask_gpt:_chrome.enter(),

        # wait for a response
        ask_gpt:_chrome.wait_for_text('Regenerate'),

        # opens and injects JavaScript into the application's element 
        # inspection console
        # arguments: browser, script, inspect element is open?
        ask_gpt:_responses.add(inject:active_inject(ask_gpt:_chrome, script(
            let m = document.getElementsByClassName(
                'flex flex-col text-sm dark:bg-gray-800'
            )[0];
            let lm = m.children[m.children.length-2];
            console.log(lm.innerText+"%$@".repeat(1000));
        ), True))
    )),

    # returns the responses and the app instance opened
    ret('chatgpt:ask_gpt', arr(ask_gpt:_chrome, ask_gpt:_responses))
), 'ask_gpt:_messages')

# asks ChatGPT a question on an open browser
function('chatgpt:active_ask_gpt', (

    # types in the URL and proceeds to the website
    if (active_ask_gpt:_enterurl, (
        active_ask_gpt:_appinstance.write('https://chat.openai.com/'),
        active_ask_gpt:_appinstance.enter()
    )),

    # waits for the message input to appear
    @ active_ask_gpt:_message_input = active_ask_gpt:_appinstance.wait_for_input('Send a message'),
    # opens the inspect element panel
    active_ask_gpt:_appinstance.inspect(),
    # responses from ChatGPT
    @ active_ask_gpt:_responses = [],

    # for each message
    active_ask_gpt:_messages.each('active_ask_gpt:_message', (

        # asks ChatGPT a question
        active_ask_gpt:_message_input.focus(),
        active_ask_gpt:_appinstance.write(active_ask_gpt:_message),
        active_ask_gpt:_appinstance.enter(),

        # wait for a response
        active_ask_gpt:_appinstance.wait_for_text('Regenerate response'),

        # opens and injects JavaScript into the application's element 
        # inspection console
        # arguments: browser, script, inspect element is open?
        active_ask_gpt:_responses.add(inject:active_inject(active_ask_gpt:_appinstance, script(
            let m = document.getElementsByClassName(
                'flex flex-col text-sm dark:bg-gray-800'
            )[0];
            let lm = m.children[m.children.length-2];
            console.log(lm.innerText+"%$@".repeat(1000));
        ), True))
    )),

    # returns the responses and the app instance opened
    ret('chatgpt:active_ask_gpt', active_ask_gpt:_responses)
), 'chatgpt:_appinstance', 'active_ask_gpt:_messages', 'active_ask_gpt:_enterurl')

# Makes a query to the ChatGPT API.
# implemented for named arguments
# 2.0.388
def('chatgpt:query', 
    &chatgpt:query:prompt=None,
    &chatgpt:query:model='gpt-3.5-turbo',
    &chatgpt:query:temperature=0.9,
    &chatgpt:query:max_tokens=150,
    &chatgpt:query:top_p=1,
    &chatgpt:query:frequency_penalty=0.0,
    &chatgpt:query:presence_penalty=0.6,
    &chatgpt:query:stop='###',
    # make the query
    ai.query(
        chatgpt:query:model,
        chatgpt:query:prompt,
        chatgpt:query:temperature,
        chatgpt:query:max_tokens,
        chatgpt:query:top_p,
        chatgpt:query:frequency_penalty,
        chatgpt:query:presence_penalty,
        chatgpt:query:stop
    )
)

# chatgpt:instance
# ChatGPT class granting greater control over a ChatGPT thread
# 2.0.388
class ('chatgpt:instance', (
    # model
    # either advanced or basic
    @ model = 'gpt-3.5-turbo',
    # retain context?
    # whether or not to keep the previous messages in the context
    @ retain_context = True,
    # messages
    @ messages = [],
    # temperature
    # how random the response is
    @ temperature = 0.9,
    # max tokens
    # how many tokens to generate
    @ max_tokens = 150,
    # top p
    # how many tokens to choose from
    @ top_p = 1,
    # frequency penalty
    # how much to penalize words that have already been used
    @ frequency_penalty = 0.0,
    # presence penalty
    # how much to penalize words that have already been used
    @ presence_penalty = 0.6,
    # stop
    # what to stop the response at
    @ stop = '###',
    
    # asks a question
    def('ask', 'self', 'chatgpt:instance:ask:prompt', (
        # return response based on model type
        # if using advanced models
       if (self.is_advanced(), (
            # add entry to messages
            self.messages(
                as('chatgpt:instance:t', self.messages(), chatgpt:instance:t.add(object(
                    'role', 'user',
                    'content', chatgpt:instance:ask:prompt
                )))
            ),
            # make a query to the advanced model
            chatgpt:query(
                &chatgpt:query:prompt=self.messages(),
                &chatgpt:query:model=self.model(),
                &chatgpt:query:temperature=self.temperature(),
                &chatgpt:query:max_tokens=self.max_tokens(),
                &chatgpt:query:top_p=self.top_p(),
                &chatgpt:query:frequency_penalty=self.frequency_penalty(),
                &chatgpt:query:presence_penalty=self.presence_penalty(),
                &chatgpt:query:stop=self.stop()
            )
        # otherwise, use the basic model
        ), ai.basic(chatgpt:instance:ask:prompt))
    )),
    # whether or not this object has an advanced model or not
    def('is_advanced', 'self', and(
        not(startswith(self.model(), 'text')), 
        not(equals(self.model(), 'gpt-3.5-turbo-instruct')))),
    # gets the number of tokens in a string for self model
    def('tokens', 'self', 'chatgpt:instance:token_str', (
        ai.tokens(chatgpt:instance:token_str, self.model()))
    )
))